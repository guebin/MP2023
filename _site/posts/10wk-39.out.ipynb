{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10wk-39: 의사결정나무 Discussion\n",
        "\n",
        "최규빈  \n",
        "2023-11-10\n",
        "\n",
        "# 1. 강의영상\n",
        "\n",
        "<https://youtu.be/playlist?list=PLQqh36zP38-y7ZQE5CtHiEraKV2eZslti&si=QYNee59zfsGgXL_X>\n",
        "\n",
        "# 2. 의사결정나무 Discussions\n",
        "\n",
        "`-` 의사결정나무 vs 선형모형\n",
        "\n",
        "1.  아이스크림+축제: 이상치에 강했음.\n",
        "2.  운동+보조제: 교호작용을 고려하지 않아도 괜찮았음.\n",
        "3.  토익유사점수: 다중공선성문제가 발생하는 경우에도 모형이 덜 망함.\n",
        "4.  밸런스게임: 필요없는 변수가 있을 경우에도 모형이 덜 망함.\n",
        "\n",
        "`-` 의사결정나무의 장점들\n",
        "\n",
        "1.  시각화가 유리하다. 설명력이 좋다.\n",
        "2.  특성(feature)의 중요도를 파악하기 용이하다.\n",
        "3.  ${\\bf y} \\sim {\\bf X}$ 사이에 존재하는 비선형성을 쉽게 모델링 할 수\n",
        "    있다. $\\to$ 쉽게 말해서 잘 맞춘다는 소리에요\n",
        "4.  모형에 대한 가정들이 필요 없다. (넌파라메트릭 모형 특징)\n",
        "\n",
        "`-` 의사결정나무의 단점: 오버피팅이 일어나기 너무 쉽다. (모형이 너무\n",
        "흔들려..)\n",
        "\n",
        "`-` 의사결정나무에 대한 자잘한 개념들 (자격증에서 잘 물어봄)\n",
        "\n",
        "**최소 샘플 분할(Min Samples Split):**\n",
        "\n",
        "-   노드를 분할하기 위한 최소 샘플 수.\n",
        "-   적절한 설정으로 과소적합 및 과적합 조절 가능.\n",
        "\n",
        "**가지치기(Pruning):**\n",
        "\n",
        "-   트리의 불필요한 부분을 제거.\n",
        "-   과적합 방지 및 모델 성능 향상에 도움.\n",
        "\n",
        "**정보 이득(Information Gain):**\n",
        "\n",
        "-   분할 전후의 엔트로피 차이를 측정.\n",
        "-   높은 정보 이득은 더 좋은 분할을 의미.\n",
        "\n",
        "**지니 불순도(Gini Impurity):**\n",
        "\n",
        "-   노드의 순도 측정 지표.\n",
        "-   낮은 지니 불순도는 높은 클래스 순도를 의미.\n",
        "\n",
        "> 결국 “트리를 어디까지 성장시킬래?”라는 물음에 대답하기 위해 고안된\n",
        "> 개념들이다. 근본적으로 “트리를 어디까지 성장시킬래?”에 대한 이론적인\n",
        "> 명확한 기술은 없다. 이는 넌파라메트릭 모형이 가지는 공통적인 특징임.\n",
        "\n",
        "`-` 의사결정나무는 오버피팅을 잡기위해서 지루한 싸움을 시작함.\n",
        "\n",
        "-   발전과정: 의사결정나무 $\\to$ 배깅, 랜덤포레스트, 부스팅\n",
        "-   의사결정나무를 응용한 다양한 방법들이 개발되었다. (너무 많아요 진짜)\n",
        "    $\\to$ 모든 방법들의 원리를 세세하게 파헤치는건 비효율적이다.\n",
        "-   그러한 다양한 방법들을 적덩히 분류해보면 대체로 배깅, 랜덤포레스트,\n",
        "    부스팅 계열로 나뉜다.[1] $\\to$ 배깅, 랜덤포레스트, 부스팅에 대한\n",
        "    공통적 아이디어를 파악하는건 효율적이다.\n",
        "-   현재 최고로 (state of the art, SOTA) 로 평가받는 알고리즘은\n",
        "    부스팅계열의 `XGBoost`, `LightGBM`, `CatBoost` 이다.\n",
        "\n",
        "[1] 모든 방법들이 세개의 카테고리중 하나에만 들어가는건 아니다"
      ],
      "id": "a7224d83-bc9a-4db9-85e0-07219b3682a7"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  }
}