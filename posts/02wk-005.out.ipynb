{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02wk-005: 타이타닉, Autogluon\n",
        "\n",
        "최규빈  \n",
        "2023-09-12\n",
        "\n",
        "# 1. 강의영상\n",
        "\n",
        "<https://youtu.be/playlist?list=PLQqh36zP38-zZrOGpLc8spPa9L39RiNhR&si=TFl5m9-VohYT_47L>\n",
        "\n",
        "# 2. Import\n",
        "\n",
        "``` python\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "```\n",
        "\n",
        "    /kaggle/input/titanic/train.csv\n",
        "    /kaggle/input/titanic/test.csv\n",
        "    /kaggle/input/titanic/gender_submission.csv"
      ],
      "id": "bcd6d7c3-6741-4415-a5e5-b037a28fb13d"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install autogluon"
      ],
      "id": "438db173-0810-4140-98cd-65314c5695af"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor"
      ],
      "id": "77a36c4a-ac65-4270-bb1e-bca688db2eb1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. 분석의 절차\n",
        "\n",
        "## A. 데이터\n",
        "\n",
        "`-` 비유: 문제를 받아오는 과정으로 비유할 수 있다."
      ],
      "id": "5eb46da6-451e-4f2b-acc9-4598e2f17753"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tr = TabularDataset(\"/kaggle/input/titanic/train.csv\")\n",
        "tst = TabularDataset(\"/kaggle/input/titanic/test.csv\")"
      ],
      "id": "7c66df28-7fe6-47de-ba1f-4d1c74976f0f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. Predictor 생성\n",
        "\n",
        "`-` 비유: 문제를 풀 학생을 생성하는 과정으로 비유할 수 있다."
      ],
      "id": "c17ef64b-4c15-4a67-8e78-ad4273ab84c7"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230910_162629/\""
          ]
        }
      ],
      "source": [
        "predictr = TabularPredictor(\"Survived\")"
      ],
      "id": "0ba98784-7f27-48dd-9b7f-6c0a738eb56c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. 적합(fit)\n",
        "\n",
        "`-` 비유: 학생이 공부를 하는 과정으로 비유할 수 있다.\n",
        "\n",
        "`-` 학습"
      ],
      "id": "bc8309da-7eb4-44a0-b85e-8d9d818add87"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230910_162629/\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #26~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jul 13 16:27:29 UTC 2\n",
            "Disk Space Avail:   306.27 GB / 490.57 GB (62.4%)\n",
            "Train Data Rows:    891\n",
            "Train Data Columns: 11\n",
            "Label Column: Survived\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "    2 unique label values:  [0, 1]\n",
            "    If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "    Available Memory:                    126262.11 MB\n",
            "    Train Data (Original)  Memory Usage: 0.31 MB (0.0% of available memory)\n",
            "    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "/home/cgb2/anaconda3/envs/mp/lib/python3.10/site-packages/autogluon/common/features/infer_types.py:118: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  result = pd.to_datetime(X, errors=\"coerce\")\n",
            "/home/cgb2/anaconda3/envs/mp/lib/python3.10/site-packages/autogluon/common/features/infer_types.py:118: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  result = pd.to_datetime(X, errors=\"coerce\")\n",
            "/home/cgb2/anaconda3/envs/mp/lib/python3.10/site-packages/autogluon/common/features/infer_types.py:118: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  result = pd.to_datetime(X, errors=\"coerce\")\n",
            "/home/cgb2/anaconda3/envs/mp/lib/python3.10/site-packages/autogluon/common/features/infer_types.py:118: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  result = pd.to_datetime(X, errors=\"coerce\")\n",
            "/home/cgb2/anaconda3/envs/mp/lib/python3.10/site-packages/autogluon/common/features/infer_types.py:118: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  result = pd.to_datetime(X, errors=\"coerce\")\n",
            "    Stage 1 Generators:\n",
            "        Fitting AsTypeFeatureGenerator...\n",
            "            Note: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "    Stage 2 Generators:\n",
            "        Fitting FillNaFeatureGenerator...\n",
            "    Stage 3 Generators:\n",
            "        Fitting IdentityFeatureGenerator...\n",
            "        Fitting CategoryFeatureGenerator...\n",
            "            Fitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "        Fitting TextSpecialFeatureGenerator...\n",
            "            Fitting BinnedFeatureGenerator...\n",
            "            Fitting DropDuplicatesFeatureGenerator...\n",
            "        Fitting TextNgramFeatureGenerator...\n",
            "            Fitting CountVectorizer for text features: ['Name']\n",
            "            CountVectorizer fit with vocabulary size = 8\n",
            "    Stage 4 Generators:\n",
            "        Fitting DropUniqueFeatureGenerator...\n",
            "    Stage 5 Generators:\n",
            "        Fitting DropDuplicatesFeatureGenerator...\n",
            "    Types of features in original data (raw dtype, special dtypes):\n",
            "        ('float', [])        : 2 | ['Age', 'Fare']\n",
            "        ('int', [])          : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
            "        ('object', [])       : 4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n",
            "        ('object', ['text']) : 1 | ['Name']\n",
            "    Types of features in processed data (raw dtype, special dtypes):\n",
            "        ('category', [])                    : 3 | ['Ticket', 'Cabin', 'Embarked']\n",
            "        ('float', [])                       : 2 | ['Age', 'Fare']\n",
            "        ('int', [])                         : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
            "        ('int', ['binned', 'text_special']) : 9 | ['Name.char_count', 'Name.word_count', 'Name.capital_ratio', 'Name.lower_ratio', 'Name.special_ratio', ...]\n",
            "        ('int', ['bool'])                   : 1 | ['Sex']\n",
            "        ('int', ['text_ngram'])             : 9 | ['__nlp__.henry', '__nlp__.john', '__nlp__.master', '__nlp__.miss', '__nlp__.mr', ...]\n",
            "    0.2s = Fit runtime\n",
            "    11 features in original data used to generate 28 features in processed data.\n",
            "    Train Data (Processed) Memory Usage: 0.07 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.2s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "    To change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 712, Val Rows: 179\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "    'NN_TORCH': {},\n",
            "    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "    'CAT': {},\n",
            "    'XGB': {},\n",
            "    'FASTAI': {},\n",
            "    'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "    'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "    'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "    0.6536   = Validation score   (accuracy)\n",
            "    0.09s    = Training   runtime\n",
            "    0.0s     = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "    0.6536   = Validation score   (accuracy)\n",
            "    0.01s    = Training   runtime\n",
            "    0.0s     = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "    0.8156   = Validation score   (accuracy)\n",
            "    0.2s     = Training   runtime\n",
            "    0.0s     = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "    0.8212   = Validation score   (accuracy)\n",
            "    0.16s    = Training   runtime\n",
            "    0.0s     = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "    0.8156   = Validation score   (accuracy)\n",
            "    0.34s    = Training   runtime\n",
            "    0.16s    = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "    0.8156   = Validation score   (accuracy)\n",
            "    0.53s    = Training   runtime\n",
            "    0.09s    = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "    0.8268   = Validation score   (accuracy)\n",
            "    0.53s    = Training   runtime\n",
            "    0.0s     = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "    0.8156   = Validation score   (accuracy)\n",
            "    0.85s    = Training   runtime\n",
            "    0.05s    = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "    0.8101   = Validation score   (accuracy)\n",
            "    0.4s     = Training   runtime\n",
            "    0.06s    = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 9: early stopping\n",
            "    0.8268   = Validation score   (accuracy)\n",
            "    1.33s    = Training   runtime\n",
            "    0.01s    = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "    0.8101   = Validation score   (accuracy)\n",
            "    0.14s    = Training   runtime\n",
            "    0.0s     = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "    0.8324   = Validation score   (accuracy)\n",
            "    1.49s    = Training   runtime\n",
            "    0.01s    = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "    0.8324   = Validation score   (accuracy)\n",
            "    0.42s    = Training   runtime\n",
            "    0.0s     = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "    0.8603   = Validation score   (accuracy)\n",
            "    0.22s    = Training   runtime\n",
            "    0.0s     = Validation runtime\n",
            "AutoGluon training complete, total runtime = 7.58s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230910_162629/\")"
          ]
        }
      ],
      "source": [
        "predictr.fit(tr) \n",
        "# 학생(predictr)에게 문제(tr)를 줘서 학습을 시킴(predictr.fit())"
      ],
      "id": "2ff440a6-2707-4849-8c16-efb51eb4f3b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 리더보드확인 (모의고사 채점)"
      ],
      "id": "57ae7048-5e1b-4167-8359-c924ebd6eab0"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0   WeightedEnsemble_L2   0.860335       0.193071  4.142821                0.000378           0.218161            2       True         14\n",
            "1         LightGBMLarge   0.832402       0.003180  0.422871                0.003180           0.422871            1       True         13\n",
            "2        NeuralNetTorch   0.832402       0.009243  1.488933                0.009243           1.488933            1       True         12\n",
            "3              CatBoost   0.826816       0.003432  0.526762                0.003432           0.526762            1       True          7\n",
            "4       NeuralNetFastAI   0.826816       0.007648  1.326021                0.007648           1.326021            1       True         10\n",
            "5              LightGBM   0.821229       0.003042  0.157547                0.003042           0.157547            1       True          4\n",
            "6            LightGBMXT   0.815642       0.003350  0.197612                0.003350           0.197612            1       True          3\n",
            "7        ExtraTreesGini   0.815642       0.050255  0.848478                0.050255           0.848478            1       True          8\n",
            "8      RandomForestEntr   0.815642       0.091255  0.525193                0.091255           0.525193            1       True          6\n",
            "9      RandomForestGini   0.815642       0.162890  0.340251                0.162890           0.340251            1       True          5\n",
            "10              XGBoost   0.810056       0.004424  0.141125                0.004424           0.141125            1       True         11\n",
            "11       ExtraTreesEntr   0.810056       0.060458  0.398653                0.060458           0.398653            1       True          9\n",
            "12       KNeighborsDist   0.653631       0.001958  0.007848                0.001958           0.007848            1       True          2\n",
            "13       KNeighborsUnif   0.653631       0.004457  0.087323                0.004457           0.087323            1       True          1"
          ]
        }
      ],
      "source": [
        "predictr.leaderboard()"
      ],
      "id": "6e513eca-aed5-420d-afca-aca5ce499dc5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## D. 예측 (predict)\n",
        "\n",
        "`-` 비유: 학습이후에 문제를 푸는 과정으로 비유할 수 있다.\n",
        "\n",
        "`-` training set 을 풀어봄 (predict) $\\to$ 점수 확인"
      ],
      "id": "73dcae2c-ad2a-48e0-b666-579f307dd5ac"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "(tr.Survived == predictr.predict(tr)).mean()"
      ],
      "id": "91daef3c-7a51-48b6-9692-3b68b04df6b9"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "(tr.Survived == (tr.Sex == \"female\")).mean() # 예전점수와 비교"
      ],
      "id": "e521d63e-3e90-413b-8b3b-89e27bf38b26"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` test set 을 풀어봄 (predict) $\\to$ 점수 확인 하러 캐글에 결과제출"
      ],
      "id": "466e4b21-e3dc-4069-beff-360259cc68e6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tst.assign(Survived = predictr.predict(tst)).loc[:,['PassengerId','Survived']]\\\n",
        ".to_csv(\"autogluon_submission.csv\",index=False)"
      ],
      "id": "fb8b17e6-2738-4e8f-a792-e02cfb025ef2"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  }
}